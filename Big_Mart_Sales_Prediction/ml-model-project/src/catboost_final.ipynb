{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c8116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "0:\tlearn: 1682.4522348\ttest: 1614.1551215\tbest: 1614.1551215 (0)\ttotal: 217ms\tremaining: 10m 50s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test2= pd.read_csv(\"test.csv\")\n",
    "# --- Step 1: Copy data ---\n",
    "df, df_test = df_train.copy(), df_test2.copy()\n",
    "\n",
    "# --- Step 2: Fill Missing Item_Weight ---\n",
    "# Create mapping of (Item_Identifier, Item_Type) -> mean Item_Weight\n",
    "item_weight_map = df.groupby(['Item_Identifier', 'Item_Type'])['Item_Weight'].mean().to_dict()\n",
    "\n",
    "# Function to fill missing Item_Weight\n",
    "def fill_item_weight(row):\n",
    "    if pd.isna(row['Item_Weight']):\n",
    "        return item_weight_map.get((row['Item_Identifier'], row['Item_Type']), np.nan)\n",
    "    return row['Item_Weight']\n",
    "\n",
    "# Apply to train and test\n",
    "df['Item_Weight'] = df.apply(fill_item_weight, axis=1)\n",
    "df['Item_Weight'] = df['Item_Weight'].fillna(df['Item_Weight'].mean())\n",
    "\n",
    "df_test['Item_Weight'] = df_test.apply(fill_item_weight, axis=1)\n",
    "df_test['Item_Weight'] = df_test['Item_Weight'].fillna(df['Item_Weight'].mean())\n",
    "# --- Step 3: Fill Missing Outlet_Size ---\n",
    "outlet_type_size_mode = df.groupby(['Outlet_Type'])['Outlet_Size'].agg(lambda x: x.mode()[0])\n",
    "df['Outlet_Size'] = df.apply(lambda row: outlet_type_size_mode[row['Outlet_Type']] if pd.isna(row['Outlet_Size']) else row['Outlet_Size'], axis=1)\n",
    "df_test['Outlet_Size'] = df_test.apply(lambda row: outlet_type_size_mode[row['Outlet_Type']] if pd.isna(row['Outlet_Size']) else row['Outlet_Size'], axis=1)\n",
    "# --- Step 3: Fill Missing Outlet_Size ---\n",
    "# Fill Outlet_Size using Outlet_Type + Outlet_Location_Type mode\n",
    "# Fill Outlet_Size using grouped mode with global fallback\n",
    "# outlet_type_size_mode = (\n",
    "#     df.groupby(['Outlet_Type', 'Outlet_Location_Type'])['Outlet_Size']\n",
    "#     .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "#     .to_dict()\n",
    "# )\n",
    "\n",
    "# global_mode = df['Outlet_Size'].mode()[0]\n",
    "\n",
    "# def fill_outlet_size(row):\n",
    "#     if pd.isna(row['Outlet_Size']):\n",
    "#         key = (row['Outlet_Type'], row['Outlet_Location_Type'])\n",
    "#         return outlet_type_size_mode.get(key, global_mode)  # fallback\n",
    "#     return row['Outlet_Size']\n",
    "\n",
    "# df['Outlet_Size'] = df.apply(fill_outlet_size, axis=1)\n",
    "# df_test['Outlet_Size'] = df_test.apply(fill_outlet_size, axis=1)\n",
    "\n",
    "# # ðŸ”‘ Fix: ensure no NaN and force string type\n",
    "# df['Outlet_Size'] = df['Outlet_Size'].astype(str).fillna(global_mode)\n",
    "# df_test['Outlet_Size'] = df_test['Outlet_Size'].astype(str).fillna(global_mode)\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 4: Standardize Fat Content ---\n",
    "fat_map = {'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg': 'Regular'}\n",
    "df['Item_Fat_Content'] = df['Item_Fat_Content'].replace(fat_map)\n",
    "df_test['Item_Fat_Content'] = df_test['Item_Fat_Content'].replace(fat_map)\n",
    "\n",
    "# --- Step 5: Feature Engineering ---\n",
    "df['Outlet_Age'] = 2025 - df['Outlet_Establishment_Year']\n",
    "df_test['Outlet_Age'] = 2025 - df_test['Outlet_Establishment_Year']\n",
    "\n",
    "df['MRP_Band'] = pd.cut(df['Item_MRP'], bins=[0,70,140,200,300], labels=['Low','Medium','High','Premium'])\n",
    "df_test['MRP_Band'] = pd.cut(df_test['Item_MRP'], bins=[0,70,140,200,300], labels=['Low','Medium','High','Premium'])\n",
    "\n",
    "\n",
    "\n",
    "df['Price_per_Unit'] = df['Item_MRP'] / df['Item_Weight']\n",
    "df_test['Price_per_Unit'] = df_test['Item_MRP'] / df_test['Item_Weight']\n",
    "\n",
    "df['Outlet_Item_Interaction'] = df['Outlet_Type'] + '_' + df['MRP_Band'].astype(str)\n",
    "df_test['Outlet_Item_Interaction'] = df_test['Outlet_Type'] + '_' + df_test['MRP_Band'].astype(str)\n",
    "\n",
    "df['Outlet_Item_Interaction1'] = df['Outlet_Size'] + '_' + df['Outlet_Age'].astype(str)+ '_' + df['Outlet_Identifier']\n",
    "df_test['Outlet_Item_Interaction1'] = df_test['Outlet_Size'] + '_' + df_test['Outlet_Age'].astype(str)+ '_' + df_test['Outlet_Identifier']\n",
    "\n",
    "# --- Step 5b: Feature Interactions ---\n",
    "df['Weight_Visibility'] = df['Item_Weight'] * df['Item_Visibility']\n",
    "df_test['Weight_Visibility'] = df_test['Item_Weight'] * df_test['Item_Visibility']\n",
    "\n",
    "df['MRP_per_Visibility'] = df['Item_MRP'] / (df['Item_Visibility'] + 1e-5)\n",
    "df_test['MRP_per_Visibility'] = df_test['Item_MRP'] / (df_test['Item_Visibility'] + 1e-5)\n",
    "\n",
    "\n",
    "# df_test['Outlet_Item_Interaction_TE'] = df_test['Outlet_Item_Interaction'].map(df['Outlet_Item_Interaction_TE'])\n",
    "# df_test['Outlet_Item_Interaction_TE'] = df_test['Outlet_Item_Interaction_TE'].fillna(global_mean)\n",
    "\n",
    "# Count frequency of each Item_Type\n",
    "item_type_counts = df['Item_Type'].value_counts()\n",
    "\n",
    "# Map counts back to dataframe\n",
    "df['Item_Type_Count'] = df['Item_Type'].map(item_type_counts)\n",
    "df_test['Item_Type_Count'] = df_test['Item_Type'].map(item_type_counts).fillna(0)\n",
    "\n",
    "# Create bands (you can adjust bins)\n",
    "df['Item_Type_Band'] = pd.cut(df['Item_Type_Count'],\n",
    "                              bins=[0, 100, 300, 600, 1000],\n",
    "                              labels=['Rare', 'Occasional', 'Common', 'Frequent']).astype(str)\n",
    "\n",
    "df_test['Item_Type_Band'] = pd.cut(df_test['Item_Type_Count'],\n",
    "                                   bins=[0, 100, 300, 600, 1000],\n",
    "                                   labels=['Rare', 'Occasional', 'Common', 'Frequent']).astype(str)\n",
    "\n",
    "# Handle zeros\n",
    "\n",
    "# Mean visibility ratio\n",
    "item_vis_mean = df.groupby('Item_Identifier')['Item_Visibility'].transform('mean')\n",
    "df['Visibility_MeanRatio'] = df['Item_Visibility'] / item_vis_mean\n",
    "item_vis_mean_test = df_test.groupby('Item_Identifier')['Item_Visibility'].transform('mean')\n",
    "df_test['Visibility_MeanRatio'] = df_test['Item_Visibility'] / item_vis_mean_test\n",
    "\n",
    "item_avg_visibility = df.groupby(['Outlet_Identifier'])['Item_Visibility'].transform('mean')\n",
    "df['Visibility_MeanRatio_2'] = df['Item_Visibility'] / item_avg_visibility\n",
    "item_avg_visibility_test = df_test.groupby(['Outlet_Identifier'])['Item_Visibility'].transform('mean')\n",
    "df_test['Visibility_MeanRatio_2'] = df_test['Item_Visibility'] / item_avg_visibility_test\n",
    "\n",
    "# --- Step 6: Prepare Features ---\n",
    "features = [\n",
    "    'Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year',\n",
    "    'Outlet_Age', 'Visibility_MeanRatio', 'Price_per_Unit', 'Outlet_Item_Interaction','Outlet_Item_Interaction1',\n",
    "    'Weight_Visibility', 'MRP_per_Visibility','Visibility_MeanRatio_2',\n",
    "    'Item_Fat_Content', 'Outlet_Type', 'Outlet_Size', 'Outlet_Location_Type', 'MRP_Band',\n",
    "    'Item_Type','Item_Type_Band', 'Item_Type_Count'\n",
    "]\n",
    "# features = [\n",
    "#     'Outlet_Type','Item_MRP','MRP_per_Visibility', 'Item_Weight']\n",
    "\n",
    "\n",
    "X = df[features]\n",
    "y = df['Item_Outlet_Sales']\n",
    "X_test_final = df_test[features]\n",
    "\n",
    "# cat_features = [ 'Outlet_Type']\n",
    "\n",
    "cat_features = ['Item_Fat_Content', 'Outlet_Type', 'Outlet_Size', 'Outlet_Location_Type', \n",
    "                'MRP_Band','Item_Type','Item_Type_Band','Item_Type_Count','Outlet_Item_Interaction','Outlet_Item_Interaction1']\n",
    "\n",
    "# --- Step 7: K-Fold Cross Validation ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_test_total = np.zeros(X_test_final.shape[0])\n",
    "val_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test_final, cat_features=cat_features)\n",
    "    \n",
    "    model = CatBoostRegressor(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.04,\n",
    "        depth=6,\n",
    "        l2_leaf_reg=10,\n",
    "        bagging_temperature=0.82,\n",
    "        eval_metric='RMSE',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100 )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "    \n",
    "    y_val_pred = (model.predict(val_pool))\n",
    "    val_rmse = np.sqrt(mean_squared_error(df['Item_Outlet_Sales'].iloc[val_idx], y_val_pred))\n",
    "    val_scores.append(val_rmse)\n",
    "    \n",
    "    y_pred_test_total += np.maximum((model.predict(test_pool)), 0) / kf.n_splits\n",
    "\n",
    "print(\"Average CV RMSE:\", np.mean(val_scores))\n",
    "\n",
    "# --- Step 8: Submission ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'Item_Identifier': df_test['Item_Identifier'],\n",
    "    'Outlet_Identifier': df_test['Outlet_Identifier'],\n",
    "    'Item_Outlet_Sales': y_pred_test_total\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_catboost_final.csv', index=False)\n",
    "print(submission_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81750be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Step 7: Hyperparameter Tuning with Optuna ---\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'iterations': trial.suggest_int('iterations', 1000, 4000),\n",
    "#         'depth': trial.suggest_int('depth', 4, 10),\n",
    "#         'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "#         'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "#         'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "#         'random_seed': 42,\n",
    "#         'eval_metric': 'RMSE',\n",
    "#         'early_stopping_rounds': 50,\n",
    "#         'verbose': 0\n",
    "#     }\n",
    "\n",
    "#     kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     val_scores = []\n",
    "\n",
    "#     for train_idx, val_idx in kf.split(X):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#         train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "#         val_pool = Pool(X_val, y_val, cat_features=cat_features)\n",
    "\n",
    "#         model = CatBoostRegressor(**params)\n",
    "#         model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "#         y_val_pred = model.predict(val_pool)\n",
    "#         val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "#         val_scores.append(val_rmse)\n",
    "\n",
    "#     return np.mean(val_scores)\n",
    "\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=20)  # adjust n_trials for more tuning\n",
    "\n",
    "# print(\"Best params:\", study.best_params)\n",
    "# print(\"Best CV RMSE:\", study.best_value)\n",
    "\n",
    "# # --- Step 8: Train final model with best params ---\n",
    "# best_params = study.best_params\n",
    "# best_params.update({\n",
    "#     'random_seed': 42,\n",
    "#     'eval_metric': 'RMSE',\n",
    "#     'early_stopping_rounds': 50,\n",
    "#     'verbose': 100\n",
    "# })\n",
    "\n",
    "# final_model = CatBoostRegressor(**best_params)\n",
    "# final_model.fit(Pool(X, y, cat_features=cat_features))\n",
    "\n",
    "# # --- Step 9: Predict on test set ---\n",
    "# test_pool = Pool(X_test_final, cat_features=cat_features)\n",
    "# y_pred_test = np.maximum(final_model.predict(test_pool), 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
